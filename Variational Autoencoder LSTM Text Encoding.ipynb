{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-based Variational Autoencoder for Text Encoding\n",
    "In this notebook I will demo the LSTM-based variational autoencoder (https://arxiv.org/pdf/1312.6114.pdf) I wrote in Keras for encoding text to a latent vector representation. This representation can be used for computing similarity metrics between documents (sentences, in this case) or as a feature vector for other learning tasks.\n",
    "\n",
    "The VAE is a generative model that maximizes the marginal probability of the input by conditioning it on a latent variable whose distribution is learned by a parameterized function estimator, such as a neural network. The neural network samples z from a normal distribution and transforms it to a distribution Q(z|X) to give us a distribution of z values given X which are likely to produce X. This is where the \"Variational\" part of VAE's comes in: we use KL-divergence in our loss function to drive Q(z|X) as close as we can to P(z), the prior distribution of z. The loss function also includes a reconstruction error term. In summary, the VAE learns an encoding distribution Q which produces latent representations z which are likely to produce the input data X, and a decoding function f(z) which is optimized to output data as close to X as it can from the latent representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamm\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\adamm\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from vae_lstm import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "We will be building our dataset by converting sentences from various NLTK corpora (Brown, Reuters, Gutenberg) into a word embedding representation which will yield a 3D tensor of shape (N, S, E), where N is the number of sentences, S is the length of the sentence (zero padded at the beginning), and E is the length of the word embedding. Here we're using S=20 and E=300. We're using the wiki-news-300d-1M.vec from https://fasttext.cc/docs/en/english-vectors.html for our word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, all_text = get_data()\n",
    "\n",
    "len_train = 50000\n",
    "len_test = 10000\n",
    "train = data[:len_train]\n",
    "train_text = all_text[:len_train]\n",
    "test = data[len_train:len_train + len_test]\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 30\n",
    "input_dim = train.shape[-1]\n",
    "timesteps = train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "We will train the model for 30 epochs with a batch size of 50. Our displayed loss is mean squared error between the generated word vectors in the output sequence and the word vectors in the input sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37751 samples, validate on 0 samples\n",
      "Epoch 1/30\n",
      "37751/37751 [==============================] - 64s 2ms/step - loss: 0.0071\n",
      "Epoch 2/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0069\n",
      "Epoch 3/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0068\n",
      "Epoch 4/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0067\n",
      "Epoch 5/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0066\n",
      "Epoch 6/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0066\n",
      "Epoch 7/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0065\n",
      "Epoch 8/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0065\n",
      "Epoch 9/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0064\n",
      "Epoch 10/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0064\n",
      "Epoch 11/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0063\n",
      "Epoch 12/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0063\n",
      "Epoch 13/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0063\n",
      "Epoch 14/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0062\n",
      "Epoch 15/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0062\n",
      "Epoch 16/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0062\n",
      "Epoch 17/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0062\n",
      "Epoch 18/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0061\n",
      "Epoch 19/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0061\n",
      "Epoch 20/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0061\n",
      "Epoch 21/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0061\n",
      "Epoch 22/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0060\n",
      "Epoch 23/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0060\n",
      "Epoch 24/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0060\n",
      "Epoch 25/30\n",
      "37751/37751 [==============================] - 58s 2ms/step - loss: 0.0060\n",
      "Epoch 26/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0060\n",
      "Epoch 27/30\n",
      "37751/37751 [==============================] - 60s 2ms/step - loss: 0.0059\n",
      "Epoch 28/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0059\n",
      "Epoch 29/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0059\n",
      "Epoch 30/30\n",
      "37751/37751 [==============================] - 59s 2ms/step - loss: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24cacfa8c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE_LSTM(input_dim=input_dim, latent_dim=100, hidden_dims=[32], timesteps=timesteps, batch_size=batch_size)\n",
    "vae, encoder, generator = model.autoencoder, model.encoder, model.generator\n",
    "\n",
    "vae.fit(train, train, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(test, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Similar Sentences\n",
    "We'll do a spot check on our model by printing the text of the most similar sentences in the encoding space for a few training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = encoder.predict(np.array(train), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[First sentence is target sentence, following are closest neighbors]\n",
      "it said after nine months following closing may require royal to register the 200 000 shares for sale . \n",
      "under terms of the letter of intent would contribute substantially to a three year exploration budget of 4 . \n",
      "to fully compensate for devaluation the quota would have to be around 28 dlrs per bag against 7 . \n",
      "economists polled by reuters said that m 1 should be anywhere from down four billion dlrs to up 2 . \n",
      "like its cousin the refrigerator a conditioner can be expected to last 20 to 25 years or more . \n",
      "economists polled by reuters said that m 1 would be anywhere from down two billion dlrs to up 1 . \n",
      "\n",
      "[First sentence is target sentence, following are closest neighbors]\n",
      "1 mln dlr defense logistics agency contract for jet fuel the defense department said . \n",
      "12 mln tonnes in 1985 the commodity board for margarine fats and oils said . \n",
      "7 mln dlrs manufactures a line of computer output to microfilm hardware and . \n",
      "13 mln tonnes editor of the hamburg based newsletter oil world said . \n",
      "87 mln ha harvested in 1986 the french maize producers ' association said . \n",
      "6 mln barrels per day bpd for the rest of 1987 oil traders said . \n",
      "\n",
      "[First sentence is target sentence, following are closest neighbors]\n",
      "he had settled accounts with him for his late agency and had talked about sundry matters of business . \n",
      "he had the black numerals on his arm so he had been branded in a concentration camp . \n",
      "he felt almost inclined to ask after all these what was a friend and what an enemy . \n",
      "he had never felt so much alive before and yet he was like a man in a trance . \n",
      "they had ruined the radar warning system with their window they had made themselves invisible above their flares . \n",
      "jane had not been gone a quarter of an hour and they had only accomplished some views of st . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_nearest_sentences(sent_idx, sentence_embeddings):\n",
    "    print(\"[First sentence is target sentence, following are closest neighbors]\")\n",
    "    for s in get_nearest_sentences(sent_idx, sentence_embeddings, train):\n",
    "        print(s)\n",
    "    print()\n",
    "        \n",
    "print_nearest_sentences(12352, encoded_sentences)\n",
    "print_nearest_sentences(5226, encoded_sentences)\n",
    "print_nearest_sentences(35233, encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model is learning some notion of sentence structure. The first example has sentences which all discuss a subject with some relationship to a number at the end of the sentence. Similarly, the second example has sentences which all begin with some number of some unit and end with a '[subject] said'. The final example has sentences which all begin with a simple '[pronoun] [verb]' structure. While sentence structure is important, the final example shows that the model may not be representing topics very well in addition to structure. Perhaps using a model like the Dirichlet Variational Autoencoder (https://arxiv.org/pdf/1811.00135.pdf), which explicitly models topics in its latent representation using a dirichlet distribution, would improve the representations in that regard.\n",
    "\n",
    "### Compare with Average Word Embedding Representation\n",
    "We can use a much simpler method for representing sentences as a vector that captures content and structure: use a weighted average of the word2vec word embeddings in the sentence matrix, since each word in a word2vec word embedding captures its contextual relationship to other words. We will simply take an unweighted average in this example, but we can imagine lemmatizing the words, weighting words in the sentence based on parts of speech and tf-idf scores, removal of stop words, and so forth to yield more meaningful sentence representations. Let's use the same examples above and see what our average sentence vectors give for the most similar sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[First sentence is target sentence, following are closest neighbors]\n",
      "it said after nine months following closing may require royal to register the 200 000 shares for sale . \n",
      "it said had a 30 day call option nine months from closing to buy from h . \n",
      "in addition the company said it authorized another 800 000 shares but would not issue them at this time . \n",
      "the company said it will lease the ships for three years and hold two additional three year options . \n",
      "said receipt of 2 500 000 shares would raise its interest in to about 59 . \n",
      "the company said it is evaluating two separate proposals and will complete the sale within 10 days . \n",
      "\n",
      "[First sentence is target sentence, following are closest neighbors]\n",
      "1 mln dlr defense logistics agency contract for jet fuel the defense department said . \n",
      "1 mln dlr provision for future losses from several major projects in defense contractor subsidiary . \n",
      "1 mln dlr defense contract refining and marketing inc is being awarded a 84 . \n",
      "9 mln dlr in credits from abroad for a planned expansion of production finance minister manuel said . \n",
      "boeing began its 37 dlr per share cash tender offer for the defense electronics firm on june two . \n",
      "8 mln dlrs in special expenses to its 1986 operations as a result of the dynamics corp settlement . \n",
      "\n",
      "[First sentence is target sentence, following are closest neighbors]\n",
      "he had settled accounts with him for his late agency and had talked about sundry matters of business . \n",
      "her husband had been extravagant and at his death about two years before had left his affairs dreadfully involved . \n",
      "he was fond of children and as he had no sons he determined to adopt one of his relations . \n",
      "his friends had imprudently supplied him with more money than is usually trusted to boys of his age . \n",
      "he had been in the apartment two days and was hazy about what had happened during that time . \n",
      "but others were up before him for to his surprise he saw a strange gentleman with his mother . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_avg_sentence_embeddings(sentence_vecs):\n",
    "    return np.average(sentence_vecs, axis=1)\n",
    "\n",
    "sentence_embeddings = get_avg_sentence_embeddings(train)\n",
    "sentence_embeddings.shape\n",
    "print_nearest_sentences(12352, sentence_embeddings)\n",
    "print_nearest_sentences(5226, sentence_embeddings)\n",
    "print_nearest_sentences(35233, sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "Rather than doing a weighted average of individual word embeddings, which loses the ordering of the sentences, we could directly learn an entire sentence embedding.\n",
    "\n",
    "Doc2vec (or Paragraph Vectors: https://arxiv.org/pdf/1405.4053v2.pdf) learns a dense vector representation of a variable length sequence of words by learning to predict the next word in a sequence given the current paragraph vector concatenated with subsequent word vectors in the sequence. Just as the LSTM-based VAE, doc2vec encodes word ordering into its representation, and doc2vec has the advantage of allowing variable sized input, where with the VAE we need a fixed size input (which we handled by zero-padding sequences to be the right size).\n",
    "\n",
    "Let's train a doc2vec model using the Python NLP package, Gensim (https://radimrehurek.com/gensim/models/doc2vec.html) and view some similarity examples from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0...epoch 1...epoch 2...epoch 3...epoch 4...epoch 5...epoch 6...epoch 7...epoch 8...epoch 9...epoch 10...epoch 11...epoch 12...epoch 13...epoch 14...epoch 15...epoch 16...epoch 17...epoch 18...epoch 19...epoch 20...epoch 21...epoch 22...epoch 23...epoch 24...epoch 25...epoch 26...epoch 27...epoch 28...epoch 29...epoch 30...epoch 31...epoch 32...epoch 33...epoch 34...epoch 35...epoch 36...epoch 37...epoch 38...epoch 39...epoch 40...epoch 41...epoch 42...epoch 43...epoch 44...epoch 45...epoch 46...epoch 47...epoch 48...epoch 49...epoch 50...epoch 51...epoch 52...epoch 53...epoch 54...epoch 55...epoch 56...epoch 57...epoch 58...epoch 59...epoch 60...epoch 61...epoch 62...epoch 63...epoch 64...epoch 65...epoch 66...epoch 67...epoch 68...epoch 69...epoch 70...epoch 71...epoch 72...epoch 73...epoch 74...epoch 75...epoch 76...epoch 77...epoch 78...epoch 79...epoch 80...epoch 81...epoch 82...epoch 83...epoch 84...epoch 85...epoch 86...epoch 87...epoch 88...epoch 89...epoch 90...epoch 91...epoch 92...epoch 93...epoch 94...epoch 95...epoch 96...epoch 97...epoch 98...epoch 99..."
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import reuters, gutenberg, brown, treebank\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = all_text\n",
    "tagged_documents = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(documents)]\n",
    "\n",
    "vector_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "d2v = Doc2Vec(vector_size=vector_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm=1)\n",
    "  \n",
    "d2v.build_vocab(tagged_documents)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('epoch {0}'.format(epoch), end='...')\n",
    "    d2v.train(tagged_documents, total_examples=d2v.corpus_count, epochs=d2v.epochs)\n",
    "    d2v.alpha -= 0.0002\n",
    "    d2v.min_alpha = d2v.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('it said after nine months following closing  montagu may require royal to register the 200  000 shares for sale .', 20408)]\n",
      "[('1 mln dlr defense logistics agency contract for jet fuel  the defense department said .', 34050)]\n",
      "[('he had settled accounts with him for his late agency  and had talked about sundry matters of business .', 28577)]\n"
     ]
    }
   ],
   "source": [
    "def find_sentence(sentences, by_words):\n",
    "    filtered = []\n",
    "    i = 0\n",
    "    for s in sentences:\n",
    "        is_found = True\n",
    "        for w in by_words:\n",
    "            if w.lower() not in s.lower():\n",
    "                is_found = False\n",
    "        if is_found:\n",
    "            filtered.append((s, i))\n",
    "        i += 1\n",
    "    return filtered\n",
    "\n",
    "# Get corresponding sentence indexes\n",
    "print(find_sentence(train_text, ['nine', 'months', 'following']))\n",
    "print(find_sentence(train_text, ['defense', 'logistics', 'agency', 'contract']))\n",
    "print(find_sentence(train_text, ['settled', 'accounts', 'sundry', 'business']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it said after nine months following closing  montagu may require royal to register the 200  000 shares for sale .\n",
      "5 mln note  company recently spun off from carter hawley hale stores inc  lt  chh .\n",
      "21 dlr an hour pay raise over the life of the new contract and improved benefits .\n",
      "31 billion avg shrs 191  100  000 vs 191  500  000 note  earnings include a loss of 3 .\n",
      "21  dlr  an  hour pay raise over the life of the new contract and improved benefits .\n",
      "rober kill has withdrawn their proposal to acquire the company ' s stock for 23 .\n",
      "\n",
      "1 mln dlr defense logistics agency contract for jet fuel  the defense department said .\n",
      "flag vessels to import 1  500 tonnes of tallow in bulk  an agent for the country said .\n",
      "agency to review johnson  johnson  lt  jnj  sweetner johnson and johnson said the u .\n",
      "agriculture department is proposing tighter federal standards setting allowable limits on insect infestations in grain shipments .\n",
      "parent bank tax payment rose to 244 mln marks last year from 233 mln in 1985 .\n",
      "on ec veg oil tax the west german government expressed support for the u .\n",
      "\n",
      "he had settled accounts with him for his late agency  and had talked about sundry matters of business .\n",
      "vivacious redhead debuts another shop  her sixth  in the governor's club hotel this week .\n",
      "appeals court last night blocked the 860 mln dlr merger of delta airlines inc  lt  dal .\n",
      "its early morning patrons were coachmen  who fortified themselves for the day with that delicacy .\n",
      "the abbey was the family seat of an opulent baronet in the neighbourhood  to whom mr .\n",
      "her acting began with the birmingham repertory company and she soon became the toast of the west end .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_most_similar(idx, topn=5):\n",
    "    print(documents[idx])\n",
    "    for s in d2v.docvecs.most_similar(str(idx), topn=topn):\n",
    "        print(documents[int(s[0])])\n",
    "    print()\n",
    "        \n",
    "print_most_similar(20408)\n",
    "print_most_similar(34050)\n",
    "print_most_similar(28577)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We would want to dig in more deeply than this cursory glance at example sentences, but it seems that our VAE encodings capture some sentence structure but are not as good at capturing topics or meaning. It may be that if we used a more sophisticated weighted average of the word embeddings to represent the sentences we could yield better content-based similarity without having to use a complicated model like the VAE. Our doc2vec model seemed to be a reasonable approach as well - given a larger corpus we would expect it to give better embeddings. We could also try using a Dirichlet Variational Autoencoder to explicitly model topic information in our latent representation of the sentences.\n",
    "\n",
    "A more principled and effective way to test the effectiveness of all of these representations against one another than simply viewing nearest neighbors of example sentences would be to measure the performance of the embeddings in various NLP tasks, such as sentiment analysis, classification, and information retrieval, with the latter being most relevant to our goal of using the representations for similarity metrics. For example, Quoc Le and Tomas Mikolov in their paragraph vectors paper which introduced the doc2vec model (https://arxiv.org/pdf/1405.4053v2.pdf) experimented with their paragraph vector representations on various tasks. They constructed an information retrieval dataset from Google search data wherein the goal was for the distance between representations of paragraphs from results in the same query to be less than the distance for a paragraph in the given query and a randomly sampled paragraph from another query. Their paragraph vector achieved only a 3.82% error rate, beating out all other tested representations (averaging word vectors to make a paragraph vector, like we did above, yielded a much higher 10.25% error rate). For future work on this demo I would want to compute these various representations on a sentiment analysis dataset, a document classification dataset, and a labeled information retrieval dataset and measure the performance of each representation type as feature vectors for the given tasks.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
